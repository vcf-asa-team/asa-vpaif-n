{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a9a62b0",
   "metadata": {},
   "source": [
    "<!-- Banner Image -->\n",
    "<center>\n",
    "    <img src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/rag-representation.jpg\" width=\"75%\">\n",
    "</center>\n",
    "\n",
    "<!-- Links -->\n",
    "<center>\n",
    "  <a href=\"https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/\" style=\"color: #76B900;\">NVIDIA AI Workbench</a> •\n",
    "  <a href=\"https://docs.nvidia.com/ai-workbench/\" style=\"color: #76B900;\">User Documentation</a> •\n",
    "  <a href=\"https://docs.nvidia.com/ai-workbench/user-guide/latest/quickstart/example-projects.html\" style=\"color: #76B900;\">Example Projects Catalog</a> •\n",
    "  <a href=\"https://forums.developer.nvidia.com/t/support-workbench-example-project-llama-3-finetune/303411\" style=\"color: #76B900;\"> Problem? Submit a ticket here! </a>\n",
    "</center>\n",
    "\n",
    "# Finetune and deploy an LLM model using SFT and VLLM \n",
    "\n",
    "Welcome!\n",
    "\n",
    "In this notebook, we're going to walk through the flow of using supervised finetuning (SFT) on the Facebook opt-125m model from scratch using the base model and then deploying it using VLLM.  \n",
    "\n",
    "Note that we will be using the base model in this notebook and not the instruct model. Additionally, we will be running through a full finetune with no quantization. This notebook was originally built for 2 A100-80GB GPUs, but the default hyperparameters have since been adjusted to run on 1x A100-80GB. If you're looking for a lighter Llama3-finetune, checkout out the other Llama3 finetuning notebook which uses Direct Preference Optimization.\n",
    "\n",
    "#### Help us make this tutorial better! Please provide feedback on the [NVIDIA Developer Forum](https://forums.developer.nvidia.com/c/ai-data-science/nvidia-ai-workbench/671).\n",
    "\n",
    "A note about running Jupyter Notebooks: Press Shift + Enter to run a cell. A * in the left-hand cell box means the cell is running. A number means it has completed. If your Notebook is acting weird, you can interrupt a too-long process by interrupting the kernel (Kernel tab -> Interrupt Kernel) or even restarting the kernel (Kernel tab -> Restart Kernel). Note restarting the kernel will require you to run everything from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0882cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run fine tuned model\n",
    "!python -O -u -m vllm.entrypoints.openai.api_server \\\n",
    "    --host=0.0.0.0 \\\n",
    "    --port=8000 \\\n",
    "    --model=output/models/fb-opt-125m-SFT \\\n",
    "    --tokenizer=facebook/opt-125m \\\n",
    "    --tensor-parallel-size=1 \\\n",
    "    --gpu-memory-utilization=0.9 \\\n",
    "    --enforce-eager \\\n",
    "    --max-model-len=2048\n",
    "    # --enable-lora \\\n",
    "    # --lora-modules peft=output/models/fb-opt-125m-SFT \\\n",
    "    # --model=facebook/opt-125m \\\n",
    "    # --model=output/models/fb-opt-125m-SFT \\\n",
    "    #--tokenizer=facebook/opt-125m \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d71aea-c9f9-4a8a-bcac-7e7a5b58e6bf",
   "metadata": {},
   "source": [
    "# Open up a terminal and run\n",
    "\n",
    "*Post finetuning test:*\n",
    "curl http://localhost:8000/v1/completions \\\n",
    "   -H \"Content-Type: application/json\" \\\n",
    "   -d '{\n",
    "       \"model\": \"output/models/fb-opt-125m-SFT\",\n",
    "       \"prompt\": \"The god father movie is\",\n",
    "       \"max_tokens\": 30,\n",
    "       \"temperature\": 0\n",
    "   }'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7d6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7d9f4-c63c-47f1-a39e-38d592629406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
