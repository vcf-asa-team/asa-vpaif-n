{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "926bada6"
   },
   "source": [
    "Copyright 2025 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "a110dfce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e624ec07"
   },
   "source": [
    "# Fine-tune Gemma 3 270M for emoji generation\n",
    "\n",
    "This notebook fine-tunes Gemma for the task of translating text into emoji using Quantized Low-Rank Adaptation (QLoRA) through the Hugging Face Transformer Reinfocement Learning ([TRL](https://huggingface.co/docs/trl/en/index)) library to help reduce memory usage and speed up the fine-tuning process.\n",
    "\n",
    "When training [Gemma 3 270M](https://huggingface.co/google/gemma-3-270m) on a NVIDIA GPU, this process can take as little as 10 minutes end-to-end. Run each code snippet to:\n",
    "\n",
    "1. Set up the JupyterLab environment\n",
    "2. Prepare a dataset for fine-tuning\n",
    "3. Load and test the base Gemma 3 270M model\n",
    "4. Fine-tune the model\n",
    "5. Test, evaluate, and save the model for further use\n",
    "\n",
    "## Set up development environment\n",
    "\n",
    "The first step is to install the necessary libraries using the `pip` package installer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEK9IfKBqQaA",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0+cu117)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.11.2)\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.25.0)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch) (15.0.7)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.56.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.23.5)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.19.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.29.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (67.7.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.3.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.40.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.26.15)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting trl\n",
      "  Downloading trl-0.24.0-py3-none-any.whl (423 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.13.1)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.2.0-py3-none-any.whl (506 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m506.3/506.3 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.21.0)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl (60.1 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf==3.20.3\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting peft\n",
      "  Downloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m504.9/504.9 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvitop\n",
      "  Downloading nvitop-1.5.3-py3-none-any.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m213.9/213.9 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.29.0)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m485.8/485.8 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.7 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m42.7/42.7 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.1)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx<1.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.1)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2025.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.5.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0+cu117)\n",
      "Collecting torch>=2.0.0 (from accelerate)\n",
      "  Downloading torch-2.9.0-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-ml-py<13.581.0a0,>=11.450.51 (from nvitop)\n",
      "  Downloading nvidia_ml_py-13.580.82-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m49.0/49.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.8.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (0.17.3)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.5.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy>=1.13.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.27.5 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.5.0 (from torch>=2.0.0->accelerate)\n",
      "  Downloading triton-3.5.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m170.3/170.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1.0.0->datasets) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1.0.0->datasets) (3.6.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.2)\n",
      "Installing collected packages: nvidia-ml-py, nvidia-cusparselt-cu12, typing-extensions, triton, tqdm, sympy, sentencepiece, safetensors, requests, pyarrow, protobuf, nvitop, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-xet, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, datasets, evaluate, bitsandbytes, accelerate, trl, peft\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.11.1\n",
      "    Uninstalling sympy-1.11.1:\n",
      "      Successfully uninstalled sympy-1.11.1\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.1.99\n",
      "    Uninstalling sentencepiece-0.1.99:\n",
      "      Successfully uninstalled sentencepiece-0.1.99\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.3.1\n",
      "    Uninstalling safetensors-0.3.1:\n",
      "      Successfully uninstalled safetensors-0.3.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.29.0\n",
      "    Uninstalling requests-2.29.0:\n",
      "      Successfully uninstalled requests-2.29.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 12.0.0\n",
      "    Uninstalling pyarrow-12.0.0:\n",
      "      Successfully uninstalled pyarrow-12.0.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.16.4\n",
      "    Uninstalling huggingface-hub-0.16.4:\n",
      "      Successfully uninstalled huggingface-hub-0.16.4\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.30.2\n",
      "    Uninstalling transformers-4.30.2:\n",
      "      Successfully uninstalled transformers-4.30.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0+cu117\n",
      "    Uninstalling torch-2.0.0+cu117:\n",
      "      Successfully uninstalled torch-2.0.0+cu117\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.13.1\n",
      "    Uninstalling datasets-2.13.1:\n",
      "      Successfully uninstalled datasets-2.13.1\n",
      "  Attempting uninstall: evaluate\n",
      "    Found existing installation: evaluate 0.4.0\n",
      "    Uninstalling evaluate-0.4.0:\n",
      "      Successfully uninstalled evaluate-0.4.0\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.21.0\n",
      "    Uninstalling accelerate-0.21.0:\n",
      "      Successfully uninstalled accelerate-0.21.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "adapter-transformers 3.2.1 requires tokenizers!=0.11.3,<0.14,>=0.11.1, but you have tokenizers 0.22.1 which is incompatible.\n",
      "tensorflow 2.11.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "torchaudio 2.0.1+cu117 requires torch==2.0.0, but you have torch 2.9.0 which is incompatible.\n",
      "torchvision 0.15.1+cu117 requires torch==2.0.0, but you have torch 2.9.0 which is incompatible.\n",
      "transformer-smaller-training-vocab 0.2.4 requires datasets<3.0.0,>=2.0.0, but you have datasets 4.2.0 which is incompatible.\n",
      "transformer-smaller-training-vocab 0.2.4 requires sentencepiece<0.2.0,>=0.1.97, but you have sentencepiece 0.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.10.1 bitsandbytes-0.48.1 datasets-4.2.0 evaluate-0.4.6 hf-xet-1.1.10 huggingface-hub-0.35.3 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-ml-py-13.580.82 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 nvitop-1.5.3 peft-0.17.1 protobuf-3.20.3 pyarrow-21.0.0 requests-2.32.5 safetensors-0.6.2 sentencepiece-0.2.1 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.0 tqdm-4.67.1 transformers-4.57.1 triton-3.5.0 trl-0.24.0 typing-extensions-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch tensorboard emoji\n",
    "%pip install -U transformers==4.57.3 trl accelerate evaluate sentencepiece bitsandbytes protobuf==3.20.3 peft nvitop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTuW1LPfLXi9"
   },
   "source": [
    "You may have the restart your session (runtime) to use newly installed libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ef3d54b"
   },
   "source": [
    "##Enable Hugging Face permissions\n",
    "To use Gemma models, you'll need to accept the model usage license and create an Access Token (already done):\n",
    "\n",
    "Specify `HF_TOKEN` from the workshop notes.  More details are provided in the Workshop Guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b6d79c93",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Login into Hugging Face Hub\n",
    "HF_TOKEN = \"<insert hf key>\"\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42c60525"
   },
   "source": [
    "## Load the dataset\n",
    "\n",
    "Hugging Face hosts a large collection of datasets for training and evaluating models. If you're not using a custom dataset, you can load a [premade dataset](https://huggingface.co/datasets/kr15t3n/g-emoji) containing examples of text and corresponding emoji translations.\n",
    "\n",
    "**If you'd like to use your own custom dataset, skip to the next step.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bc3BYl72pWhp",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd75c79010e4bd6b06d04f618921b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97197749748462ba716a37525bf50f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129154481ce4433b9f4bd02bb341bd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2529 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcf707890cd429b8d08ab2196565a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2529 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here's the 10th example from the dataset: {'text': 'A supernova just exploded', 'emoji': '汳･笨ｨ'}\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Use the first 2000 samples for efficient training.\n",
    "general_dataset_path = load_dataset(\"kr15t3n/text2emoji\", encoding=\"utf-8\", split=\"train\")\n",
    "\n",
    "# Clean dataset to only use examples where 'emoji' field contains only emoji characters\n",
    "def is_only_emoji(sample):\n",
    "  emoji_string = sample['emoji']\n",
    "  if not emoji_string:\n",
    "    return False\n",
    "  return all(emoji.is_emoji(char) for char in emoji_string)\n",
    "dataset = general_dataset_path.filter(is_only_emoji)\n",
    "\n",
    "print(f\"\\nHere's the 10th example from the dataset: {dataset[10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0eb2e06"
   },
   "source": [
    "## Load the model\n",
    "\n",
    "You can access [Gemma 3 270M](https://huggingface.co/google/gemma-3-270m-it) from Hugging Face Hub by accepting the license terms. The instruction-tuned version of the model has already been trained on how to follow directions and with fine-tuning, you'll now adapt it to a new task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "18069ed2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fc0e45d51445e095e087e6a26959dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /opt/conda/lib/python3.10/site-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2025-10-19 01:22:22.465242: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-19 01:22:22.919643: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-19 01:22:24.592441: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-10-19 01:22:24.592603: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-10-19 01:22:24.592614: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8754996f3d5343adb4bdba083ec09b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b501d82636d4d92978720b056270263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8488c7ad85974d619c3e0639936d72ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec2a9b1286f418f9e67221e81be81a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f978557d58aa40bda385c8e834eb60eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ba296bebf147b0a5c73170dbbb09e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ad893d8f1845e09aab7a512f1b777e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62dd249774d245788738fc4acaf78533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "DType: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "gemma_model = \"google/gemma-3-270m-it\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(gemma_model, device_map=\"auto\", attn_implementation=\"eager\", dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(gemma_model)\n",
    "\n",
    "print(f\"Device: {base_model.device}\")\n",
    "print(f\"DType: {base_model.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hI4twbrz0xj"
   },
   "source": [
    "Device should print as `cuda` if you're using a GPU runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PafivP8u1Gv9"
   },
   "source": [
    "### Format the training dataset\n",
    "Now that you've loaded your data, format the training dataset into conversational roles, including the text input and emoji output, plus a system prompt that contains the direction to the model. This helps the model learn how to interpret the 'text' and 'emoji' columns from your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VWz32s5h074E",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59eb1e255a004b6b97e2f272e62e378a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here's the 40th example from the formatted training dataset:\n",
      "{'messages': [{'content': 'Translate this text to emoji: ', 'role': 'system'}, {'content': 'Avoiding responsibilities', 'role': 'user'}, {'content': '沛汳ｨ', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def translate(sample):\n",
    "  return {\n",
    "      \"messages\": [\n",
    "          {\"role\": \"system\", \"content\": \"Translate this text to emoji: \"},\n",
    "          {\"role\": \"user\", \"content\": f\"{sample['text']}\"},\n",
    "          {\"role\": \"assistant\", \"content\": f\"{sample['emoji']}\"}\n",
    "      ]\n",
    "  }\n",
    "\n",
    "training_dataset = dataset.map(translate, remove_columns=dataset.features.keys())\n",
    "training_dataset_splits = training_dataset.train_test_split(test_size=0.1, shuffle=True)\n",
    "\n",
    "print(\"\\nHere's the 40th example from the formatted training dataset:\")\n",
    "print(training_dataset[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3w3b9-O4fDz"
   },
   "source": [
    "### Recommended: Test the base model\n",
    "\n",
    "Let's first check how the base model's ability to respond to the instruction \"Translate this text to emoji\"\n",
    "\n",
    "Try testing it a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "u8L0_INJyUok",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset text: Chasing sunsets and dreams.\n",
      "\n",
      "Dataset emoji: 沍沛汳ｭ汳問惠\n",
      "\n",
      "Model generated output: 沽岩惠\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from random import randint\n",
    "import re\n",
    "\n",
    "# Create a transformers inference pipeline\n",
    "pipe = pipeline(\"text-generation\", model=gemma_model, tokenizer=tokenizer)\n",
    "\n",
    "# Select a random sample from the test dataset\n",
    "rand_idx = randint(0, len(training_dataset_splits[\"test\"]) - 1)\n",
    "test_sample = training_dataset_splits[\"test\"][rand_idx]\n",
    "\n",
    "# Handle messages\n",
    "all_messages = test_sample['messages']\n",
    "user_message_content = next((msg['content'].strip() for msg in all_messages if msg['role'] == 'user'), \"Not Found\")\n",
    "dataset_emoji = next((msg['content'].strip() for msg in all_messages if msg['role'] == 'assistant'), \"Not Found\")\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Translate this text to emoji: \"},\n",
    "    {\"role\": \"user\", \"content\": user_message_content}\n",
    "]\n",
    "\n",
    "# Apply the chat template. This will format the messages correctly for the model.\n",
    "prompt = tokenizer.apply_chat_template(prompt_messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# Generate the output\n",
    "output = pipe(prompt, max_new_tokens=64)\n",
    "model_output_only = output[0]['generated_text'][len(prompt):].strip()\n",
    "\n",
    "print(f\"\\nDataset text: {user_message_content}\")\n",
    "print(f\"\\nDataset emoji: {dataset_emoji}\")\n",
    "print(f\"\\nModel generated output: {model_output_only}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ph26HDJgua3W"
   },
   "source": [
    "The base model output may not meet your expectations窶蚤nd that's okay!\n",
    "\n",
    "Gemma 3 270M was designed for task specialization, which means it can improve performance for specific tasks when trained with representative examples. Let's fine-tune the model for more reliable outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbd9fc1b"
   },
   "source": [
    "## Fine-tune the model\n",
    "\n",
    "Hugging Face [TRL](https://huggingface.co/docs/trl/index) provides tools for training and fine-tuning LLMs using memory-efficient techniques like QLoRA (Quantized Low-Rank Adaptation) to train adapters on top of a frozen quantized version of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BJFoOdL0y8w"
   },
   "source": [
    "### Configure the tuning job\n",
    "Define the training configuration for the Gemma 3 base model:\n",
    "\n",
    "1. `BitsandBytesConfig` to quantize the model for memory efficiency\n",
    "2. `LoraConfig` for parameter-efficient fine-tuning\n",
    "2. `SFTConfig` for supervised fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qiIj1ADc-exw",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configured\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig\n",
    "\n",
    "adapter_path = \"content/myemoji-gemma-adapters\"      # Where to save your LoRA adapters\n",
    "tokenizer = AutoTokenizer.from_pretrained(gemma_model)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=\"all-linear\",                      # Target all linear layers\n",
    "    lora_dropout=0.05,                                # Increase to 0.1 to induce overfitting\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    modules_to_save=[\"lm_head\", \"embed_tokens\"]       # Save the lm_head and embed_tokens as you train the special tokens\n",
    ")\n",
    "\n",
    "args = SFTConfig(\n",
    "    output_dir=adapter_path,                          # Directory to save adapters\n",
    "    num_train_epochs=3,                               # Number of training epochs\n",
    "    per_device_train_batch_size=4,                    # Batch size per device during training\n",
    "    logging_strategy=\"epoch\",                         # Log every epoch\n",
    "    eval_strategy=\"epoch\",                            # Evaluate loss metrics every epoch\n",
    "    save_strategy=\"epoch\",                            # Save checkpoint every epoch\n",
    "    learning_rate=5e-5,                               # Learning rate,\n",
    "    lr_scheduler_type=\"constant\",                     # Use constant learning rate scheduler\n",
    "    max_length=256,                                   # Max sequence length for model and packing of the dataset\n",
    "    gradient_checkpointing=False,                     # Use gradient checkpointing to save memory\n",
    "    packing=False,                                    # Groups multiple samples in the dataset into a single sequence\n",
    "    optim=\"adamw_torch_fused\",                        # Use fused adamw optimizer\n",
    "    report_to=\"tensorboard\",                          # Report metrics to tensorboard\n",
    "    weight_decay=0.01,                                # Added weight decay for regularization\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(gemma_model, quantization_config=bnb_config, device_map=\"auto\", attn_implementation='eager')\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "print(\"Training configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd88e798",
    "tags": []
   },
   "source": [
    "### Start training\n",
    "\n",
    "`SFTTrainer` tokenizes the datasets and trains the base model using the hyperparameters from the previous step.\n",
    "\n",
    "The training time varies based on a range of factors, such as the size of your dataset or number of epochs. Using a a100 (8c) GPU, this takes about 10 minutes for 1000 training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WqacJNeU9v7b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fe32676c7840988627efea28fd8c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/1367 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf813a72504418693beb69e56db56c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/1367 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76aa8c73f04442e852d0389ec4e086b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b143966494476e8e43a3c4d37f6874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 2, 'pad_token_id': 0}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1026' max='1026' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1026/1026 04:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.688800</td>\n",
       "      <td>1.280116</td>\n",
       "      <td>1.360404</td>\n",
       "      <td>38561.000000</td>\n",
       "      <td>0.743120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.109600</td>\n",
       "      <td>1.238205</td>\n",
       "      <td>1.118954</td>\n",
       "      <td>77122.000000</td>\n",
       "      <td>0.752376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.909400</td>\n",
       "      <td>1.273045</td>\n",
       "      <td>0.845347</td>\n",
       "      <td>115683.000000</td>\n",
       "      <td>0.750734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA adapters saved to content/myemoji-gemma-adapters\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "# Set training and evaluation datasets\n",
    "train_dataset = training_dataset_splits['train']\n",
    "eval_dataset = training_dataset_splits['test']\n",
    "\n",
    "# Train and save the LoRA adapters\n",
    "trainer = SFTTrainer(\n",
    "    model=base_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=lora_config,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model(adapter_path)\n",
    "\n",
    "print(f\"LoRA adapters saved to {adapter_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDvGlb5xO34z"
   },
   "source": [
    "The LoRA adapters for each training checkpoint (epoch) will be saved in content folder. Now, you can evaluate the training and validation loss metrics to choose which adapters to merge with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xll8zZ3_u8Mt"
   },
   "source": [
    "### Plot training results\n",
    "To evaluate the model, you can plot the training and validation losses using Matplotlib to visualize these metrics over training steps or epochs. This helps monitor the training process and make informed decisions about hyperparameters or early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vPN-DTopaUIy",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Access the log history\n",
    "log_history = trainer.state.log_history\n",
    "\n",
    "# Extract training / validation loss\n",
    "train_losses = [log[\"loss\"] for log in log_history if \"loss\" in log]\n",
    "epoch_train = [log[\"epoch\"] for log in log_history if \"loss\" in log]\n",
    "eval_losses = [log[\"eval_loss\"] for log in log_history if \"eval_loss\" in log]\n",
    "epoch_eval = [log[\"epoch\"] for log in log_history if \"eval_loss\" in log]\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(epoch_train, train_losses, label=\"Training Loss\")\n",
    "plt.plot(epoch_eval, eval_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyIwS-orvWzd"
   },
   "source": [
    "Training loss measures the error on the data the model was trained on. Validation loss measures the error on a separate dataset the model has not seen before. Monitoring both helps detect overfitting (when the model performs well on training data but poorly on unseen data).\n",
    "\n",
    "- validation loss >> training loss: **overfitting**\n",
    "- validation loss > training loss: **some overfitting**\n",
    "- validation loss < training loss: **some underfitting**\n",
    "- validation loss << training loss: **underfitting**\n",
    "\n",
    "If your task requires memorization of specific examples, or specific emoji to be generated for a given text, overfitting can be beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILgEZvZ71Edz"
   },
   "source": [
    "### Merge the adapters\n",
    "\n",
    "Once trained you can merge the LoRA adapters with the model. You can choose which adapters to merge by specifying the training checkpoint folder, otherwise it will default to the last epoch.\n",
    "* For better task generalization, choose the most underfit checkpoint (validation loss < training loss)\n",
    "* For better memorization of specific examples, choose the most overfit (checkpoint > training loss)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "A7e5BQ9U06Q2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model merged and saved to content/myemoji-gemma-merged/. Final model vocabulary size: 262144\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "adapter_path = \"content/myemoji-gemma-adapters/\"                 # Choose which adapters to merge, otherwise defaults to latest\n",
    "merged_model_path = \"content/myemoji-gemma-merged/\"              # Location of merged model directory\n",
    "\n",
    "# Load base model and tokenizer\n",
    "base_model = AutoModelForCausalLM.from_pretrained(gemma_model, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "\n",
    "# Load and merge the PEFT adapters onto the base model\n",
    "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Save the merged model and its tokenizer\n",
    "model.save_pretrained(merged_model_path)\n",
    "tokenizer.save_pretrained(merged_model_path)\n",
    "\n",
    "print(f\"Model merged and saved to {merged_model_path}. Final model vocabulary size: {model.config.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf86e31d"
   },
   "source": [
    "### Test the fine-tuned model\n",
    "\n",
    "Let's compare your fine-tuned model performance against the base model! Test a few inputs by updating `text_to_translate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Create Transformers inference pipeline\n",
    "merged_model = AutoModelForCausalLM.from_pretrained(merged_model_path, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(merged_model_path)\n",
    "pipe = pipeline(\"text-generation\", model=merged_model, tokenizer=tokenizer)\n",
    "pipe_base = pipeline(\"text-generation\", model=gemma_model, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28R3pRN_hai7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuned model output: 沛厄ｸ条沍嬉沽蚕n",
      "\n",
      "Base model output: \n"
     ]
    }
   ],
   "source": [
    "# Test a prompt\n",
    "text_to_translate = \"let's go to the beach\"  #@param {type:\"string\"}\n",
    "inference_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Translate this text to emoji: \"},\n",
    "    {\"role\": \"user\", \"content\": text_to_translate}\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(inference_messages, tokenize=False, add_generation_prompt=True)\n",
    "output = pipe(prompt, max_new_tokens=128)\n",
    "output_base = pipe_base(prompt, max_new_tokens=128)\n",
    "model_output = output[0]['generated_text'][len(prompt):].strip()\n",
    "model_output_base = output_base[0]['generated_text'][len(prompt):].strip()\n",
    "\n",
    "print(f\"\\nFine-tuned model output: {model_output}\")\n",
    "\n",
    "print(f\"\\nBase model output: {model_output_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86qPcFbHH_kh"
   },
   "source": [
    "Does the model output the emoji you'd expect?\n",
    "\n",
    "If you're not getting the results you want, you can try [using different hyperparameters](#scrollTo=-BJFoOdL0y8w) to train the model, or updating your training dataset to contain more representative examples.\n",
    "\n",
    "Once you're happy with the results, you can save your model to Hugging Face Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H12D9g4X_peV"
   },
   "source": [
    "## Save your model and upload to Harbor\n",
    "**You now have a customized Gemma 3 270M model! 沁**\n",
    "\n",
    "Upload it to a repository on Harbor so you easily share your model or access it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure the harbor FQDN is correct\n",
    "harbor=\"r169-env4-harbor.pse.lab\"\n",
    "harborUser=\"admin\"\n",
    "harborPassword=\"Harbor12345\"\n",
    "model=\"workshop01/gemma-3-270m-it-ft\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H12D9g4X_peV"
   },
   "source": [
    "## Install and configure the VCF CLI\n",
    "Downloads the latest vcf cli and installs the PAIS plugin for push/pull models in Harbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-19 17:02:50--  https://packages.broadcom.com/artifactory/vcf-distro/vcf-cli/linux/amd64/v9.0.1/vcf-cli.tar.gz\n",
      "Resolving packages.broadcom.com (packages.broadcom.com)... 44.226.59.123, 100.21.156.46, 54.185.186.5\n",
      "Connecting to packages.broadcom.com (packages.broadcom.com)|44.226.59.123|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 \n",
      "Location: https://jfrog-prod-usw2-shared-oregon-main.s3.amazonaws.com/aol-broadcom/filestore/52/526ed958b0f582284246333d3924b9240904e6d3?X-Artifactory-username=anonymous&X-Artifactory-repoType=local&X-Artifactory-repositoryKey=vcf-distro&X-Artifactory-originPackageType=generic&X-Artifactory-packageType=generic&X-Artifactory-artifactPath=vcf-cli%2Flinux%2Famd64%2Fv9.0.1%2Fvcf-cli.tar.gz&X-Artifactory-originProjectKey=default&X-Artifactory-projectKey=default&X-Artifactory-originRepoType=local&X-Artifactory-originRepositoryKey=vcf-distro&x-jf-traceId=d393fc89209762a1db7548adcbdb0c62&response-content-disposition=attachment%3Bfilename%3D%22vcf-cli.tar.gz%22&response-content-type=application%2Fx-gzip&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDEaCXVzLXdlc3QtMiJIMEYCIQDbIyAzyE0%2F5wyukMUMVHMJPS3sdfDUgX%2FH%2Bs0z9DHVlAIhANFts5W2KuzY61k3ElUTZPqj0is5Wmr6f8kC6q2eeVmLKo8FCNr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQABoMMTUyMTUzMDYyMTQxIgy5s9WjnQePYzgzG5sq4wRD3Mv4RWQw2wm%2FfFc2GEwT7w4xk7Oq0Y1eMlxRHbIi6sW7oJLk52G4zTTJt%2BaEFRX%2Fkvn9%2FAACd7qExE5wa2z%2FQhGiEuMccogUHXBYUcSd5NXJ6xbw2DkvbwJknfvD0G3kTs4oAWgU3PI5%2BI7jwFfvAaq3P9yeDinJZc0rqatMUY4nb4kWzMYtKp8GdsNFHu2Vlc8MP%2FZpLgAcOzOnXjYoi%2Bh33BtSIG9AsYZd4gU6DTaTHfKcje3i7vP4FNTNbI1x5LmU7Q%2Fx5jJjcoF0NlxCMfghKGynWnFDsHwqcVNEoP6EPRXNUdmaUJ27ata8EAsDOg7ZLP1GGQXYvgOB5HIGJ0JqcDQey6KikelK2jP%2B2%2BM94%2FTFpUWIhf%2BbmtAKqzdF6BwsgPX0ZRsYJmH4JNOHQnC3fTclUt0eXP60qI9NwDtAnbWTXCIoEXdwxgIz0Jq7jZFhV0OSfrZc7W3HWW5BeDM6W0frNysCIOfjYj5xQK6oE77zYoWOde%2B7%2FZfDd200f3OFCVBkfv88v08Jxo%2BCHPdSu0DpakiHoT3jzEijX1bdipuq0Tvf5jg7vUc%2BvzVhdVeRJKq%2FNVqIG0MYcg8pq%2FE%2B%2B%2Fnl%2FKv9AUesQnUfxs0NnltftjekhUlHkWTL16MW9Vk5c30Owl4kCrL2tf3a3b4AwkyjlYBUQYfTe0K96AOfAp0AvDZywqL6%2FRp18ZQDqVbv0eWSWkFYDu7h1Z%2FmCW9rIZzy8%2BH2JuAfur6xwu4n6FBySJoDtA1azh1NFSpGB0paOc8m9muUKGv6o0f5F4kK2ZrM3zMi8MDSNCPjOyPkxTD2stTHBjqZAVuZVgNnnucYqRU70VGBtRYW4eZx2byqBeifnVMIANqBcCKLxNbIt6YedXtcpY1aoimassqJOWdsEMRDREy%2BbAykBNJFyNDb3vgED3Yf7wPmfk30esOIJ2AoCG%2FLVOEbGk7BWwOdHNKsdWnlU2ozjZ6vnR5t%2B664DAxOLEACTUEDXEX%2FgCF1KJCm9U6X4cSixT68SvJpr%2BXTUA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251019T170250Z&X-Amz-SignedHeaders=host&X-Amz-Expires=600&X-Amz-Credential=ASIASG3IHPL6QOLUFGV7%2F20251019%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=33b430aee80fbf62d63a8a5993174a50a8b00e11c38635fc71992a6536771128 [following]\n",
      "--2025-10-19 17:02:50--  https://jfrog-prod-usw2-shared-oregon-main.s3.amazonaws.com/aol-broadcom/filestore/52/526ed958b0f582284246333d3924b9240904e6d3?X-Artifactory-username=anonymous&X-Artifactory-repoType=local&X-Artifactory-repositoryKey=vcf-distro&X-Artifactory-originPackageType=generic&X-Artifactory-packageType=generic&X-Artifactory-artifactPath=vcf-cli%2Flinux%2Famd64%2Fv9.0.1%2Fvcf-cli.tar.gz&X-Artifactory-originProjectKey=default&X-Artifactory-projectKey=default&X-Artifactory-originRepoType=local&X-Artifactory-originRepositoryKey=vcf-distro&x-jf-traceId=d393fc89209762a1db7548adcbdb0c62&response-content-disposition=attachment%3Bfilename%3D%22vcf-cli.tar.gz%22&response-content-type=application%2Fx-gzip&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDEaCXVzLXdlc3QtMiJIMEYCIQDbIyAzyE0%2F5wyukMUMVHMJPS3sdfDUgX%2FH%2Bs0z9DHVlAIhANFts5W2KuzY61k3ElUTZPqj0is5Wmr6f8kC6q2eeVmLKo8FCNr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQABoMMTUyMTUzMDYyMTQxIgy5s9WjnQePYzgzG5sq4wRD3Mv4RWQw2wm%2FfFc2GEwT7w4xk7Oq0Y1eMlxRHbIi6sW7oJLk52G4zTTJt%2BaEFRX%2Fkvn9%2FAACd7qExE5wa2z%2FQhGiEuMccogUHXBYUcSd5NXJ6xbw2DkvbwJknfvD0G3kTs4oAWgU3PI5%2BI7jwFfvAaq3P9yeDinJZc0rqatMUY4nb4kWzMYtKp8GdsNFHu2Vlc8MP%2FZpLgAcOzOnXjYoi%2Bh33BtSIG9AsYZd4gU6DTaTHfKcje3i7vP4FNTNbI1x5LmU7Q%2Fx5jJjcoF0NlxCMfghKGynWnFDsHwqcVNEoP6EPRXNUdmaUJ27ata8EAsDOg7ZLP1GGQXYvgOB5HIGJ0JqcDQey6KikelK2jP%2B2%2BM94%2FTFpUWIhf%2BbmtAKqzdF6BwsgPX0ZRsYJmH4JNOHQnC3fTclUt0eXP60qI9NwDtAnbWTXCIoEXdwxgIz0Jq7jZFhV0OSfrZc7W3HWW5BeDM6W0frNysCIOfjYj5xQK6oE77zYoWOde%2B7%2FZfDd200f3OFCVBkfv88v08Jxo%2BCHPdSu0DpakiHoT3jzEijX1bdipuq0Tvf5jg7vUc%2BvzVhdVeRJKq%2FNVqIG0MYcg8pq%2FE%2B%2B%2Fnl%2FKv9AUesQnUfxs0NnltftjekhUlHkWTL16MW9Vk5c30Owl4kCrL2tf3a3b4AwkyjlYBUQYfTe0K96AOfAp0AvDZywqL6%2FRp18ZQDqVbv0eWSWkFYDu7h1Z%2FmCW9rIZzy8%2BH2JuAfur6xwu4n6FBySJoDtA1azh1NFSpGB0paOc8m9muUKGv6o0f5F4kK2ZrM3zMi8MDSNCPjOyPkxTD2stTHBjqZAVuZVgNnnucYqRU70VGBtRYW4eZx2byqBeifnVMIANqBcCKLxNbIt6YedXtcpY1aoimassqJOWdsEMRDREy%2BbAykBNJFyNDb3vgED3Yf7wPmfk30esOIJ2AoCG%2FLVOEbGk7BWwOdHNKsdWnlU2ozjZ6vnR5t%2B664DAxOLEACTUEDXEX%2FgCF1KJCm9U6X4cSixT68SvJpr%2BXTUA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251019T170250Z&X-Amz-SignedHeaders=host&X-Amz-Expires=600&X-Amz-Credential=ASIASG3IHPL6QOLUFGV7%2F20251019%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=33b430aee80fbf62d63a8a5993174a50a8b00e11c38635fc71992a6536771128\n",
      "Resolving jfrog-prod-usw2-shared-oregon-main.s3.amazonaws.com (jfrog-prod-usw2-shared-oregon-main.s3.amazonaws.com)... 52.92.212.201, 3.5.82.80, 52.218.186.11, ...\n",
      "Connecting to jfrog-prod-usw2-shared-oregon-main.s3.amazonaws.com (jfrog-prod-usw2-shared-oregon-main.s3.amazonaws.com)|52.92.212.201|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 150670336 (144M) [application/x-gzip]\n",
      "Saving to: 窶vcf-cli.tar.gz窶兔n",
      "\n",
      "vcf-cli.tar.gz      100%[===================>] 143.69M  34.9MB/s    in 5.4s    \n",
      "\n",
      "2025-10-19 17:02:56 (26.5 MB/s) - 窶vcf-cli.tar.gz窶 saved [150670336/150670336]\n",
      "\n",
      "._vcf-cli-linux_amd64\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.provenance'\n",
      "vcf-cli-linux_amd64\n",
      "[i] Refreshing plugin inventory cache for \"projects.packages.broadcom.com/vcf-cli/plugins/plugin-inventory:latest\", this will take a few seconds.\n",
      "\u001b[K[i] Reinitialized plugin 'pais:v2.0.51' installed. Reinitializing...\u001b[?25h\n",
      "[ok] successfully installed 'pais' plugin\n"
     ]
    }
   ],
   "source": [
    "!wget https://packages.broadcom.com/artifactory/vcf-distro/vcf-cli/linux/amd64/v9.0.2/vcf-cli.tar.gz\n",
    "!tar -vxf vcf-cli.tar.gz\n",
    "!mv vcf-cli-linux_amd64 vcf\n",
    "!chmod +x vcf\n",
    "!./vcf plugin install pais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H12D9g4X_peV"
   },
   "source": [
    "## Install Docker\n",
    "Leverage Docker to authenticate with Harbor before we push our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease               \u001b[0m\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                 \u001b[0m\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease               \u001b[0m\u001b[33m\n",
      "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:6 https://packagecloud.io/github/git-lfs/ubuntu jammy InRelease     \u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done                                 \u001b[33m\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "175 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[1;33mW: \u001b[0mhttps://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ca-certificates is already the newest version (20240203~22.04.1).\n",
      "curl is already the newest version (7.81.0-1ubuntu1.21).\n",
      "software-properties-common is already the newest version (0.99.22.9).\n",
      "apt-transport-https is already the newest version (2.4.14).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 175 not upgraded.\n",
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease               \u001b[0m\n",
      "Get:3 https://download.docker.com/linux/ubuntu jammy InRelease [48.5 kB]      \u001b[0m\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease                         \u001b[0m\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease       \u001b[0mm     \u001b[0m\u001b[33m\u001b[33m\u001b[33m\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease     \u001b[0m\u001b[33m\n",
      "Get:8 https://download.docker.com/linux/ubuntu jammy/stable amd64 Packages [69.9 kB]\n",
      "Hit:7 https://packagecloud.io/github/git-lfs/ubuntu jammy InRelease[33m        \u001b[0m\u001b[33m\u001b[33m\n",
      "Fetched 118 kB in 1s (108 kB/s)                               \u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "175 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[1;33mW: \u001b[0mhttps://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  docker-buildx-plugin docker-compose-plugin\n",
      "Suggested packages:\n",
      "  docker-model-plugin\n",
      "The following NEW packages will be installed:\n",
      "  docker-buildx-plugin docker-ce-cli docker-compose-plugin\n",
      "0 upgraded, 3 newly installed, 0 to remove and 175 not upgraded.\n",
      "Need to get 46.6 MB of archives.\n",
      "After this operation, 200 MB of additional disk space will be used.\n",
      "Get:1 https://download.docker.com/linux/ubuntu jammy/stable amd64 docker-buildx-plugin amd64 0.29.1-1~ubuntu.22.04~jammy [15.9 MB]\n",
      "Get:2 https://download.docker.com/linux/ubuntu jammy/stable amd64 docker-ce-cli amd64 5:28.5.1-1~ubuntu.22.04~jammy [16.5 MB]\n",
      "Get:3 https://download.docker.com/linux/ubuntu jammy/stable amd64 docker-compose-plugin amd64 2.40.1-1~ubuntu.22.04~jammy [14.3 MB]\n",
      "Fetched 46.6 MB in 1s (37.0 MB/s)               \u001b[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package docker-buildx-plugin.\n",
      "(Reading database ... 66689 files and directories currently installed.)\n",
      "Preparing to unpack .../docker-buildx-plugin_0.29.1-1~ubuntu.22.04~jammy_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking docker-buildx-plugin (0.29.1-1~ubuntu.22.04~jammy) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 15%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package docker-ce-cli.\n",
      "Preparing to unpack .../docker-ce-cli_5%3a28.5.1-1~ubuntu.22.04~jammy_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking docker-ce-cli (5:28.5.1-1~ubuntu.22.04~jammy) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Selecting previously unselected package docker-compose-plugin.\n",
      "Preparing to unpack .../docker-compose-plugin_2.40.1-1~ubuntu.22.04~jammy_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Unpacking docker-compose-plugin (2.40.1-1~ubuntu.22.04~jammy) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Setting up docker-buildx-plugin (0.29.1-1~ubuntu.22.04~jammy) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up docker-compose-plugin (2.40.1-1~ubuntu.22.04~jammy) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [########################################..................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up docker-ce-cli (5:28.5.1-1~ubuntu.22.04~jammy) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "#install docker so we can authenticate with harbor\n",
    "!sudo apt update\n",
    "!sudo apt install -y apt-transport-https ca-certificates curl software-properties-common\n",
    "!curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n",
    "!echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
    "!sudo apt update\n",
    "!sudo apt install -y docker-ce-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H12D9g4X_peV"
   },
   "source": [
    "## Log in to Harbor\n",
    "Use Docker to log into harbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rp-r169-env1-harbor.pse.lab\n",
      "depth=0 CN = harbor\n",
      "verify error:num=20:unable to get local issuer certificate\n",
      "verify return:1\n",
      "depth=0 CN = harbor\n",
      "verify error:num=21:unable to verify the first certificate\n",
      "verify return:1\n",
      "depth=0 CN = harbor\n",
      "verify return:1\n",
      "DONE\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "rehash: warning: skipping ca-certificates.crt,it does not contain exactly one certificate or CRL\n",
      "1 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "done.\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "\n",
      "WARNING! Your credentials are stored unencrypted in '/home/jovyan/.docker/config.json'.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/go/credential-store/\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!echo {harbor}\n",
    "!openssl s_client -showcerts -servername {harbor} -connect {harbor}:443 </dev/null | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' > {harbor}.crt\n",
    "\n",
    "!sudo cp {harbor}.crt /usr/local/share/ca-certificates/{harbor}.crt\n",
    "!sudo update-ca-certificates\n",
    "!docker login {harbor} -u {harborUser} -p {harborPassword}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H12D9g4X_peV"
   },
   "source": [
    "## Push the Fine-Tuned Model to Harbor using PAIS\n",
    "Run the vcf pais cli command to push the model to the workshop project in Harbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workshop01/gemma-3-270m-it-ft\n",
      "/home/jovyan/content/myemoji-gemma-merged\n",
      "added_tokens.json    generation_config.json   tokenizer_config.json\n",
      "chat_template.jinja  model.safetensors\t      tokenizer.json\n",
      "config.json\t     special_tokens_map.json  tokenizer.model\n",
      "Image Digest: sha256:dae4147de9dd0d44187cdcd5f4305a31724b6645f76edfaf9a7876fe7287bf37\n",
      "Tag: v1\n",
      "To pull this exact model, use\n",
      "   /home/jovyan/.local/share/vcf-cli/pais/v2.0.51_e34ad3bd14caaf0752756928784f9f9e3cd640e49539a5f66c5a348fe39d529d models pull --modelStore rp-r169-env1-harbor.pse.lab/workshop --modelName workshop01/gemma-3-270m-it-ft --digest sha256:dae4147de9dd0d44187cdcd5f4305a31724b6645f76edfaf9a7876fe7287bf37\n"
     ]
    }
   ],
   "source": [
    "# copy the model to Harbor using vcf pais\n",
    "# update the workshop number before running\n",
    "!echo {model}\n",
    "%cd /home/jovyan/content/myemoji-gemma-merged\n",
    "!ls\n",
    "!/home/jovyan/vcf pais models push --modelStore {harbor}/workshop --modelName {model} -t v1\n",
    "%cd /home/jovyan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6f8ff452"
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered how to efficiently fine-tune Gemma 3 270M for emoji generation. Continue on to the conversion and quantization steps to get it ready for on-device deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Fine_tune_Gemma_3_270M_for_emoji_generation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
